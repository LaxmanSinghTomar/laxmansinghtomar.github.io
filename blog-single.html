<!DOCTYPE html>
<!--[if lt IE 9 ]><html class="no-js oldie" lang="en"> <![endif]-->
<!--[if IE 9 ]><html class="no-js oldie ie9" lang="en"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>

    <!--- basic page needs
    ================================================== -->
    <meta charset="utf-8">
    <title>Blog Single - Hola</title>
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- mobile specific metas
    ================================================== -->
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- CSS
    ================================================== -->
    <link rel="stylesheet" href="css/base.css">
    <link rel="stylesheet" href="css/vendor.css">
    <link rel="stylesheet" href="css/main.css">

    <!-- script
    ================================================== -->
    <script src="js/modernizr.js"></script>
    <script src="js/pace.min.js"></script>

    <!-- favicons
    ================================================== -->
    <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
    <link rel="icon" href="favicon.ico" type="image/x-icon">

</head>


<body id="top">

    <!-- header
    ================================================== -->
    <header class="s-header">
            
        <div class="header-logo">
            <a class="site-logo" href="index.html"><img src="images/logo.png" alt="Homepage"></a>
        </div>

        <nav class="header-nav-wrap">
            <ul class="header-nav">
                <li><a href="index.html#home" title="home">Home</a></li>
                <li><a href="index.html#about" title="about">About</a></li>
                <li><a href="index.html#works" title="works">Works</a></li>
                <li class="current"><a href="blog.html" title="blog">Blog</a></li>
                <li><a href="index.html#contact" title="contact">Contact</a></li>	
            </ul>
        </nav>

        <a class="header-menu-toggle" href="#0"><span>Menu</span></a>

    </header> <!-- end s-header -->


    <article class="blog-single">

        <!-- page header/blog hero
        ================================================== -->
        <div class="page-header page-header--single page-hero" style="background-image:url(images/blog/blog-bg-02.jpg)">
        
            <div class="row page-header__content narrow">
                <article class="col-full">
                    <div class="page-header__info">
                        <div class="page-header__cat">
                            <a href="#0">Dimensionality Reduction</a><a href="#0">Machine Learning</a>
                        </div>
                    </div>
                    <h1 class="page-header__title">
                        <a href="#0" title="">
                            Dimensionality Reduction using PCA & SVD.
                        </a>
                    </h1>
                    <ul class="page-header__meta">
                        <li class="date">October 21, 2019</li>
                        <li class="author">
                            By
                            <span>Laxman Singh Tomar</span>
                        </li>
                    </ul>
                    
                </article>
            </div>
    
        </div> <!-- end page-header -->

        <div class="row blog-content">
            <div class="col-full blog-content__main">

                <p class="lead">Whenever we start a data analysis problem, one of the most initial steps that we undergo is some sort of exploratory data analysis of raw data at hand. Exploring your data is a crucial step as until you have basic understanding of your data viz structure of it, it's somewhat difficult to know whether the data you've is suitable for the task we gotta perform or is something from which we can draw any insights. In real world problems, raw data consists of many features. On one hand it's good to have multiple features as it allows our models to generalize well, but on the other it's bad as we can only work things out for visualizations upto 3 dimensions. So how can we go on exploring our data? The answer to this problem is Dimensionality Reduction. Dimensionality Reduction helps us out by providing a simpler and more compact representations of our original raw data to either aid our understanding or to provide useful input for the incoming stages of analysis. Here we'll focus on two such techniques one by one.</p>
                
                <p>What happens is, whenever we have a problem at hand or we're trying to understand some underlying phenomenon, in order to do so we measure various quantities potentially related to it. In most cases, if we knew exactly what to measure in advance, we might be able to find some simple relationships in our data. Say, when we have a mensuration problem, most of the time we know which formula will work things out for us. So we just try to find values which can be plugged into formula equation. But sadly, generally we aren't that fortunate and don't know what we got to measure, so we often end up measure anything that might be relevant and end up having irrelevant or redundant signals in our measurements. To make this a bit more concrete, let's try to generate a 2-dimensional dataset which can explain what we just proposed:

                </p>

                <p>
                <img src="images/dimensionality%20reduction-2000.png" 
                     srcset="images/dimensionality reduction-2000.jpg 2000w, 
                        images/dimensionality reduction-1000.jpg 1000w, 
                        images/dimensionality reduction-500.jpg 500w" 
                     sizes="(max-width: 2000px) 100vw, 2000px" alt="">
                </p>
                
                <p>Now it's pretty evident from the plot that there's a linear relationship between the 2 variables, thus we probably don't need to include both of them as ùë•1 can be easily explained by ùë•2 and vice versa.</p>

                <h2>Principal Component Analysis (PCA)</h2>

                <p>Now you know that there might exist some features which may be redundant as their behavior can be explained by other features, we should be able to summarize the data with less features. So, what PCA does to solve this issue is: Instead of simply picking out the useful features and discarding the others it uses a linear combination of the existing features and constructs some new features that are better alternative representation of original data. In our 2-dimensional dataset above, PCA will try to pick the best single direction, or often referred as first principal component in 2D, and project our points onto that single direction. Immediately the next question arises, out of the many possible lines in 2-dimension, which line should we pick?</p>
                
                <p>
                <img 
                     src="images/pca two views-2000.png" 
                     srcset="images/pca two views-2000.jpg 2000w, 
                        images/pca two views-1000.jpg 1000w, 
                        images/pca two views-500.jpg 500w" 
                     sizes="(max-width: 2000px) 100vw, 2000px" alt="">
                </p>

                <p>It turns out that, there are couple of different answers to this question. First of them would be that we're looking for some features that strongly differ across data points, thus PCA looks for features that captures as much as variation across data points as possible. Second answer would be that we're looking for the features that would allow us to reconstruct the original features. Imagine that we come up with a feature that has little do with the original features we had, if we were to use this new feature, there's no way we can relate this to the original features. So no point in taking this up! Hence, PCA looks for features that minimizes the reconstruction error.</p>
                
                <p>So, behavior of PCA can be explained by both these outlooks; shown in figure above. Here black dot represent original data points, black line represents the projected line, red dot on the left represents the points on the projected line and the red line represents the reconstruction error.</p>
                
                <p>Suprisingly, it turns out that these 2 objectives are equivalent and PCA can do both of them simulatenously. To see, why minimizing the sum of the squared residuals is equivalent to maximizing variance consider the 2 dimension visualization below:</p>
                
                <p>
                <img 
                     src="images/objective-2000.png" 
                     srcset="images/objective-2000.png 2000w, 
                        images/objective-1000.png 1000w, 
                        images/objective-500.png 500w" 
                     sizes="(max-width: 2000px) 100vw, 2000px" alt="">
                </p>

                
                
                <p>Consider a datapoint. The contribution of this specific data point to the total variance is the squared Euclidean length. Applying the Pythagorean theorem shows that this total variance equals the sum of variance lost(thr squared residual) and variance remaining. Thus, it's equivalent to either maximizing remaining variance or minimizing lost variance to find the principal components.</p>


                <a href="https://github.com/LaxmanSinghTomar/Machine-Learning/blob/master/Tutorials/Dimensionality%20Reduction.ipynb">For full implementation of PCA from scratch!</a>
                
                <h4>Important Takeaways</h4>
                <p>For the identification of underlying patterns existing in our data, we often look for variation across observations to distinguish them from one another. Hence it seems reasonable to be able to find a succinct representation that best captures the variation in our initial raw data. PCA, in particular looks to explain our data via it's maximum directions of variance. By compressing a higher dimensional dataset into a lower one, while still retaining most of the variance(information) allows us to:</p>
                
                
                <ol>
                    <li>Perform Visualizations by reducing the number of dimensions for a high-dimensional dataset.</li>
                    
                    
                    <li>Speeds up Machine Learning Algorithms by reducing the amount of memory required to train the algorithms with less number of features.</li>
                </ol>
                

                <p class="blog-content__tags">
                    <span>Post Tags</span>

                    <span class="blog-content__tag-list">
                        <a href="#0">orci</a>
                        <a href="#0">lectus</a>
                        <a href="#0">varius</a>
                        <a href="#0">turpis</a>
                    </span>

                </p>

                <div class="blog-content__pagenav">
                    <div class="blog-content__nav">
                        <div class="blog-content__prev">
                            <a href="#0" rel="prev">
                                <span>Previous Post</span>
                                Tips on Minimalist Design 
                            </a>
                        </div>
                        <div class="blog-content__next">
                            <a href="#0" rel="next">
                                <span>Next Post</span>
                                Less Is More 
                            </a>
                        </div>
                    </div>

                    <div class="blog-content__all">
                        <a href="blog.html" class="btn btn--primary">
                            View All Post
                        </a>
                    </div>
                </div>

            </div><!-- end blog-content__main -->
        </div> <!-- end blog-content -->

    </article>

    <!-- footer
    ================================================== -->
    <footer>
            <div class="row">
                <div class="col-full">
    
                    <div class="footer-logo">
                        <a class="footer-site-logo" href="#0"><img src="images/logo.png" alt="Homepage"></a>
                    </div>
    
                    <ul class="footer-social">
                        <li><a href="https://www.linkedin.com/in/laxman-singh">
                            <i class="im im-linkedin" aria-hidden="true"></i>
                            <span>Linkedin</span>
                        </a></li>
                        <li><a href="https://twitter.com/LxmnSinghTomar">
                            <i class="im im-twitter" aria-hidden="true"></i>
                            <span>Twitter</span>
                        </a></li>
                        <li><a href="https://www.github.com/LaxmanSinghTomar">
                            <i class="im im-github" aria-hidden="true"></i>
                            <span>Github</span>
                        </a></li>
                        <li><a href="#0">
                            <i class="im im-facebook" aria-hidden="true"></i>
                            <span>Facebook</span>
                        </a></li>
                    </ul>
                        
                </div>
            </div>
    
            <div class="row footer-bottom">
    
                <div class="col-twelve">
                    <div class="copyright">
                        <span>¬© Copyright Laxman 2019</span> 
                        <span>Design by <a href="https://laxmansinghtomar.github.io">Laxman</a></span>	
                    </div>
    
                    <div class="go-top">
                    <a class="smoothscroll" title="Back to Top" href="#top"><i class="im im-arrow-up" aria-hidden="true"></i></a>
                    </div>
                </div>
    
            </div> <!-- end footer-bottom -->
    
        </footer> <!-- end footer -->
    
    
        <div id="preloader"> 
            <div id="loader"></div>
        </div>
    
    
        <!-- Java Script
        ================================================== -->
        <script src="js/jquery-3.2.1.min.js"></script>
        <script src="js/plugins.js"></script>
        <script src="js/main.js"></script>

</body>

</html>